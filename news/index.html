<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> news | Yihao LIU </title> <meta name="author" content="Yihao LIU"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lyh-18.github.io/news/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yihao</span> LIU </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">news</h1> <p class="post-description"></p> </header> <article> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Sep 10, 2025</th> <td> We are excited to announce <strong>Lumina-DiMOO</strong>, our latest unified multimodal generation and understanding model built upon an advanced discrete diffusion architecture. This framework demonstrates the strong potential of multimodal diffusion large language models (dLLM) to unify diverse tasks within a single, streamlined architecture, while delivering state-of-the-art performance that surpasses many existing unified models. Learn more and explore resources: <a href="https://synbol.github.io/Lumina-DiMOO/" rel="external nofollow noopener" target="_blank">[Homepage]</a> <a href="https://github.com/Alpha-VLLM/Lumina-DiMOO" rel="external nofollow noopener" target="_blank">[GitHub]</a> <a href="https://huggingface.co/Alpha-VLLM/Lumina-DiMOO" rel="external nofollow noopener" target="_blank">[HuggingFace]</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 01, 2025</th> <td> We introduce <strong>ArtiMuse</strong>, a multimodal large language model (MLLM) for professional aesthetic understanding, which is trained on <strong>ArtiMuse-10K</strong>, a meticulously curated, expert-annotated dataset. ArtiMuse-10K systematically defines eight explainable and fine-grained aesthetic attributes (e.g., Composition &amp; Design, Visual Elements &amp; Structure), with a wide coverage of diverse visual domains, including graphic design, 3D design, AIGC-generated images, photography, and painting &amp; calligraphy. <a href="https://arxiv.org/abs/2507.14533" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://thunderbolt215.github.io/ArtiMuse-project/" rel="external nofollow noopener" target="_blank">[Homepage]</a> <a href="https://github.com/thunderbolt215/ArtiMuse" rel="external nofollow noopener" target="_blank">[GitHub]</a> <a href="https://artimuse.intern-ai.org.cn/" rel="external nofollow noopener" target="_blank">[Online Demo v1.0]</a> Note: ArtiMuse was officially released at <strong>WAIC 2025</strong>, in the forum “Evolving with AI: The Iteration and Resilience of Artistic Creativity”. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 26, 2025</th> <td> Our video restoration method <em>DiffVSR</em> was accepted by <strong>ICCV2025</strong>. <a href="https://arxiv.org/abs/2501.10110" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://xh9998.github.io/DiffVSR-project/" rel="external nofollow noopener" target="_blank">[Homepage]</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 22, 2025</th> <td> Our video colorization method <a href="https://github.com/lyh-18/TCVC-Temporally-Consistent-Video-Colorization" rel="external nofollow noopener" target="_blank">TCVC</a> has won the <strong>CVMJ 2025 Best Paper Honorable Mention Award</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 01, 2025</th> <td> We present <strong>Lunima-OmniLV</strong> (abbreviated as OmniLV), a universal multimodal multi-task framework for low-level vision that addresses over 100 sub-tasks across four major categories, including image restoration, image enhancement, weak-semantic dense prediction, and stylization. <a href="https://arxiv.org/abs/2504.04903" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://andrew0613.github.io/OmniLV_page/" rel="external nofollow noopener" target="_blank">[Homepage]</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 18, 2024</th> <td> <em>GenLV</em> was accepted by <strong>ACM MM2024</strong>. GenLV is a successive work of PromptGIP, which further broadens the tasks and improves performance. The paper can be found at <a href="https://dl.acm.org/doi/pdf/10.1145/3664647.3681621" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 01, 2024</th> <td> Two papers were accepted by <strong>ECCV2024</strong>. By analyzing the relationships between image degradations, <a href="https://arxiv.org/abs/2407.12273" rel="external nofollow noopener" target="_blank">GRIDS</a> propose a grouped learning method to deal with multiple-degradation restoration. <a href="https://github.com/Andrew0613/X-Restormer" rel="external nofollow noopener" target="_blank">X-Restormer</a> is a new general image restoration backbone network, which possesses good task generality and achieves competitive performance across a variety of restoration tasks. </td> </tr> <tr> <th scope="row" style="width: 20%">May 02, 2024</th> <td> <em>PromptGIP</em> was accepted by <strong>ICML2024</strong>. PromptGIP is a universal model for general image processing that covers image restoration, image enhancement, image feature extraction tasks, etc. Code is available at <a href="https://github.com/lyh-18/PromptGIP" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 27, 2023</th> <td> One paper was accepted by <strong>TPAMI</strong>. <a href="https://github.com/lyh-18/SRGA" rel="external nofollow noopener" target="_blank">SRGA</a> is the first quantitative indicator for measuring the generalization ability of blind super-resolution deep models. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 25, 2023</th> <td> Two papers were accepted by <strong>CVPR2023</strong>. <a href="https://github.com/lyh-18/DegAE_DegradationAutoencoder" rel="external nofollow noopener" target="_blank">DegAE</a> is a new pretraining paradigm for low-level vision. <a href="https://github.com/haoyuc/MaskedDenoising" rel="external nofollow noopener" target="_blank">MaskedDenoising</a> adopts masked training to enhance the generalization performance of denoising networks. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 12, 2023</th> <td> Our video colorization method <em>TCVC</em> was accepted by <strong>CVMJ</strong>. Code is available at <a href="https://github.com/lyh-18/TCVC-Temporally-Consistent-Video-Colorization" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 25, 2022</th> <td> Our survey on <strong>Blind Image Super-Resolution</strong> has been accepted by <strong>TPAMI</strong>. <a href="https://ieeexplore.ieee.org/abstract/document/9870558" rel="external nofollow noopener" target="_blank">Paper Link</a> </td> </tr> <tr> <th scope="row" style="width: 20%">May 30, 2022</th> <td> The extention version of the lightweight photo retouching network <em>CSRNet</em> has been accepted by <strong>TMM</strong>. Paper links: <a href="https://link.springer.com/chapter/10.1007/978-3-030-58601-0_40" rel="external nofollow noopener" target="_blank">conference version</a>, <a href="https://arxiv.org/abs/2104.06279" rel="external nofollow noopener" target="_blank">journal version</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 31, 2020</th> <td> We have won the <strong>3rd place</strong> of <a href="https://rlq-tod.github.io/challenge2.html" rel="external nofollow noopener" target="_blank">UDC2020 Challenge on Image Restoration of Under-Display Camera</a> (in conjunction with ECCV2020). The technique report of the proposed RDUnet model can be found at <a href="https://link.springer.com/chapter/10.1007/978-3-030-68238-5_30" rel="external nofollow noopener" target="_blank">here</a>. The official challenge report can be found at <a href="https://arxiv.org/pdf/2008.07742" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 26, 2020</th> <td> We have won the <strong>1st place</strong> of <a href="https://data.vision.ee.ethz.ch/cvl/aim20/" rel="external nofollow noopener" target="_blank">AIM2020 Video Temporal Super-Resolution Challenge</a> (in conjunction with ECCV2020). The technique report of the proposed <em>EQVI</em> model can be found at <a href="https://arxiv.org/abs/2009.04642" rel="external nofollow noopener" target="_blank">here</a>. Code is available at <a href="https://github.com/haoyuc/MaskedDenoising" rel="external nofollow noopener" target="_blank">here</a>. The official challenge report can be found at <a href="https://arxiv.org/pdf/2009.12987" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 18, 2020</th> <td> Our proposed lightweight photo retouching method <a href="https://link.springer.com/chapter/10.1007/978-3-030-58601-0_40" rel="external nofollow noopener" target="_blank">CSRNet</a> was accepted by <strong>ECCV2020</strong>. </td> </tr> </table> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yihao LIU. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>