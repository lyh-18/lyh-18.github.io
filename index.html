<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Yihao LIU </title> <meta name="author" content="Yihao LIU"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lyh-18.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Yihao</span> LIU </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/photo_lyh-480.webp 480w,/assets/img/photo_lyh-800.webp 800w,/assets/img/photo_lyh-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/photo_lyh.jpg?2a6f2d313595af8a51ef5ca30cf783c4" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="photo_lyh.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <table> <tbody> <tr> <td><a href="https://scholar.google.com/citations?user=WRIYcNwAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google scholar</a></td> <td><a href="https://github.com/lyh-18" rel="external nofollow noopener" target="_blank">Github</a></td> </tr> </tbody> </table> <p>I am a Research Scientist at the Shanghai Artificial Intelligence Laboratory, where I lead a team focusing on <strong>multimodal generation and understanding</strong>. I earned my Bachelor’s degree in 2018 and my Ph.D. in 2023, both from the University of Chinese Academy of Sciences (<a href="http://www.ucas.ac.cn/" rel="external nofollow noopener" target="_blank">UCAS</a>). During my doctoral studies, I was affiliated with the Shenzhen Institutes of Advanced Technology (SIAT), Chinese Academy of Sciences, under the supervision of Prof. <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Yu Qiao</a> and Prof. <a href="https://scholar.google.com/citations?user=OSDCB0UAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Chao Dong</a>. My research lies at the intersection of computer vision, generative modeling, and scientific intelligence, with particular emphasis on multimodal foundation models and image/video enhancement.</p> <p>Throughout my student journey, I have been honored with prestigious awards, including the President’s Award of the Chinese Academy of Sciences, the Zhu Li Yue Hua Outstanding Doctoral Student Award, the CAS Excellent Youth League Member Award, the Beijing Outstanding Graduate Award, the SIAT President’s Innovation Award, as well as the CVMJ 2025 Best Paper Honorable Mention Award.</p> <p>I have also excelled in multiple international and national competitions, such as 1st place in the PIRM 2018 Perceptual Image Super-Resolution Challenge, 1st place in the AIM 2020 Video Frame Interpolation Challenge, 2nd place in the NTIRE 2021 HDR Enhancement Challenge, 3rd place in the UDC 2020 Under-Display Camera Restoration Challenge. I serve as a reviewer for various top journals and conferences, including TPAMI, TIP, TCSVT, TMM, CVPR, ICCV, ECCV, NeurIPS, etc.</p> <p><strong>Current Research Focus</strong></p> <p>My current research focuses on pioneering a new generation of multimodal foundation models that integrate generation and understanding within a unified architecture. Specifically:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">Unified Multimodal Architectures</code>: Designing new-generation frameworks (e.g., discrete diffusion, autoregressive hybrids) that integrate text, image, video, and audio tasks, enabling coherent cross-modal representation, reasoning, and generation.</li> <li> <code class="language-plaintext highlighter-rouge">Knowledge-Driven and Causality-Aware Modeling</code>: Embedding structured world knowledge, physical realism, and causal reasoning into multimodal models, moving beyond perceptual fidelity toward scientifically grounded and logically consistent outputs.</li> <li> <code class="language-plaintext highlighter-rouge">General Low-Level Vision Models</code>: Consolidating diverse low-level vision tasks — restoration, enhancement, style transfer, and dense prediction — into a robust multimodal framework, advancing detail recovery, fidelity, and generalization for real-world applications.</li> <li> <code class="language-plaintext highlighter-rouge">Post-training and Reward Alignment</code>: Developing multimodal alignment and reinforcement learning paradigms, incorporating human preference modeling and expert feedback, to ensure outputs that are not only high-quality and aesthetic but also reliable, interpretable, and scientifically valid.</li> </ul> <p>I am open to collaboration and discussions. Feel free to reach out at liuyihao14@mails.ucas.ac.cn or liuyihao@pjlab.org.cn</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 01, 2025</th> <td> We introduce <strong>ArtiMuse</strong>, a multimodal large language model (MLLM) for professional aesthetic understanding, which is trained on <strong>ArtiMuse-10K</strong>, a meticulously curated, expert-annotated dataset. ArtiMuse-10K systematically defines eight explainable and fine-grained aesthetic attributes (e.g., Composition &amp; Design, Visual Elements &amp; Structure), with a wide coverage of diverse visual domains, including graphic design, 3D design, AIGC-generated images, photography, and painting &amp; calligraphy. <a href="https://arxiv.org/abs/2507.14533" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://thunderbolt215.github.io/ArtiMuse-project/" rel="external nofollow noopener" target="_blank">[Homepage]</a> <a href="https://github.com/thunderbolt215/ArtiMuse" rel="external nofollow noopener" target="_blank">[GitHub]</a> <a href="https://artimuse.intern-ai.org.cn/" rel="external nofollow noopener" target="_blank">[Online Demo v1.0]</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 26, 2025</th> <td> Our video restoration method <em>DiffVSR</em> was accepted by <strong>ICCV2025</strong>. <a href="https://arxiv.org/abs/2501.10110" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://xh9998.github.io/DiffVSR-project/" rel="external nofollow noopener" target="_blank">[Homepage]</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 22, 2025</th> <td> Our video colorization method <a href="https://github.com/lyh-18/TCVC-Temporally-Consistent-Video-Colorization" rel="external nofollow noopener" target="_blank">TCVC</a> has won the <strong>CVMJ 2025 Best Paper Honorable Mention Award</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 01, 2025</th> <td> We present <strong>Lunima-OmniLV</strong> (abbreviated as OmniLV), a universal multimodal multi-task framework for low-level vision that addresses over 100 sub-tasks across four major categories, including image restoration, image enhancement, weak-semantic dense prediction, and stylization. <a href="https://arxiv.org/abs/2504.04903" rel="external nofollow noopener" target="_blank">[Paper]</a> <a href="https://andrew0613.github.io/OmniLV_page/" rel="external nofollow noopener" target="_blank">[Homepage]</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 18, 2024</th> <td> <em>GenLV</em> was accepted by <strong>ACM MM2024</strong>. GenLV is a successive work of PromptGIP, which further broadens the tasks and improves performance. The paper can be found at <a href="https://dl.acm.org/doi/pdf/10.1145/3664647.3681621" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 01, 2024</th> <td> Two papers were accepted by <strong>ECCV2024</strong>. By analyzing the relationships between image degradations, <a href="https://arxiv.org/abs/2407.12273" rel="external nofollow noopener" target="_blank">GRIDS</a> propose a grouped learning method to deal with multiple-degradation restoration. <a href="https://github.com/Andrew0613/X-Restormer" rel="external nofollow noopener" target="_blank">X-Restormer</a> is a new general image restoration backbone network, which possesses good task generality and achieves competitive performance across a variety of restoration tasks. </td> </tr> <tr> <th scope="row" style="width: 20%">May 02, 2024</th> <td> <em>PromptGIP</em> was accepted by <strong>ICML2024</strong>. PromptGIP is a universal model for general image processing that covers image restoration, image enhancement, image feature extraction tasks, etc. Code is available at <a href="https://github.com/lyh-18/PromptGIP" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 27, 2023</th> <td> One paper was accepted by <strong>TPAMI</strong>. <a href="https://github.com/lyh-18/SRGA" rel="external nofollow noopener" target="_blank">SRGA</a> is the first quantitative indicator for measuring the generalization ability of blind super-resolution deep models. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/grids-480.webp 480w,/assets/img/publication_preview/grids-800.webp 800w,/assets/img/publication_preview/grids-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/grids.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="grids.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="cao2025grids" class="col-sm-8"> <div class="title">GRIDS: Grouped Multiple-Degradation Restoration with Image Degradation Similarity</div> <div class="author"> Shuo Cao<sup>*</sup>, <em>Yihao Liu<sup>*</sup></em>, Wenlong Zhang, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In European Conference on Computer Vision</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/x-restormer-480.webp 480w,/assets/img/publication_preview/x-restormer-800.webp 800w,/assets/img/publication_preview/x-restormer-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/x-restormer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="x-restormer.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2025comparative" class="col-sm-8"> <div class="title">A Comparative Study of Image Restoration Networks for General Backbone Network Design</div> <div class="author"> Xiangyu Chen, Zheyuan Li, Yuandong Pu, <em>Yihao Liu</em>, Jiantao Zhou, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In European Conference on Computer Vision</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICML</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/promptgip-480.webp 480w,/assets/img/publication_preview/promptgip-800.webp 800w,/assets/img/publication_preview/promptgip-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/promptgip.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="promptgip.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2024unifying" class="col-sm-8"> <div class="title">Unifying Image Processing as Visual Prompting Question Answering</div> <div class="author"> <em>Yihao Liu<sup>*</sup></em>, Xiangyu Chen<sup>*</sup>, Xianzheng Ma<sup>*</sup>, Xintao Wang, Jiantao Zhou, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In Proceedings of the 41st International Conference on Machine Learning (ICML)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACM MM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/genlv-480.webp 480w,/assets/img/publication_preview/genlv-800.webp 800w,/assets/img/publication_preview/genlv-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/genlv.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="genlv.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2024learning" class="col-sm-8"> <div class="title">Learning A Low-Level Vision Generalist via Visual Task Prompt</div> <div class="author"> Xiangyu Chen, <em>Yihao Liu</em>, Yuandong Pu, Wenlong Zhang, Jiantao Zhou, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM International Conference on Multimedia</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVMJ</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tcvc-480.webp 480w,/assets/img/publication_preview/tcvc-800.webp 800w,/assets/img/publication_preview/tcvc-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/tcvc.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tcvc.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2024temporally" class="col-sm-8"> <div class="title">Temporally Consistent Video Colorization with Deep Feature Propagation and Self-Regularization Learning</div> <div class="author"> <em>Yihao Liu<sup>*</sup></em>, Hengyuan Zhao<sup>*</sup>, Kelvin CK Chan, Xintao Wang, Chen Change Loy, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>Computational Visual Media</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/degae-480.webp 480w,/assets/img/publication_preview/degae-800.webp 800w,/assets/img/publication_preview/degae-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/degae.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="degae.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2023degae" class="col-sm-8"> <div class="title">DegAE: A New Pretraining Paradigm for Low-Level Vision</div> <div class="author"> <em>Yihao Liu</em>, Jingwen He, Jinjin Gu, Xiangtao Kong, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TPAMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/srga-480.webp 480w,/assets/img/publication_preview/srga-800.webp 800w,/assets/img/publication_preview/srga-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/srga.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="srga.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2023evaluating" class="col-sm-8"> <div class="title">Evaluating the Generalization Ability of Super-Resolution Networks</div> <div class="author"> <em>Yihao Liu</em>, Hengyuan Zhao, Jinjin Gu, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>IEEE Transactions on pattern analysis and machine intelligence</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/maskeddenoising-480.webp 480w,/assets/img/publication_preview/maskeddenoising-800.webp 800w,/assets/img/publication_preview/maskeddenoising-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/maskeddenoising.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="maskeddenoising.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="chen2023masked" class="col-sm-8"> <div class="title">Masked Image Training for Generalizable Deep Image Denoising</div> <div class="author"> Haoyu Chen, Jinjin Gu, <em>Yihao Liu</em>, Salma Abdel Magid, Chao Dong, Qiong Wang, Hanspeter Pfister, and Lei Zhu </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TPAMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cp3-480.webp 480w,/assets/img/publication_preview/cp3-800.webp 800w,/assets/img/publication_preview/cp3-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/cp3.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cp3.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="xu2023cp3" class="col-sm-8"> <div class="title">CP3: Unifying Point Cloud Completion by Pretrain-Prompt-Predict Paradigm</div> <div class="author"> Mingye Xu, Yali Wang, <em>Yihao Liu</em>, Tong He, and Yu Qiao </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TMM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/csrnet-l-480.webp 480w,/assets/img/publication_preview/csrnet-l-800.webp 800w,/assets/img/publication_preview/csrnet-l-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/csrnet-l.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="csrnet-l.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2022very" class="col-sm-8"> <div class="title">Very Lightweight Photo Retouching Network with Conditional Sequential Modulation</div> <div class="author"> <em>Yihao Liu<sup>*</sup></em>, Jingwen He<sup>*</sup>, Xiangyu Chen, Zhengwen Zhang, Hengyuan Zhao, Chao Dong, and Yu Qiao </div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TPAMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bsr_survey-480.webp 480w,/assets/img/publication_preview/bsr_survey-800.webp 800w,/assets/img/publication_preview/bsr_survey-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/bsr_survey.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bsr_survey.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2022blind" class="col-sm-8"> <div class="title">Blind Image Super-Resolution: A Survey and Beyond</div> <div class="author"> Anran Liu, <em>Yihao Liu</em>, Jinjin Gu, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>IEEE transactions on pattern analysis and machine intelligence</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TPAMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ranksrgan-j-480.webp 480w,/assets/img/publication_preview/ranksrgan-j-800.webp 800w,/assets/img/publication_preview/ranksrgan-j-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/ranksrgan-j.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ranksrgan-j.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2021ranksrgan" class="col-sm-8"> <div class="title">RankSRGAN: Super Resolution Generative Adversarial Networks with Learning to Rank</div> <div class="author"> Wenlong Zhang, <em>Yihao Liu</em>, Chao Dong, and Yu Qiao </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TPAMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cresmd-480.webp 480w,/assets/img/publication_preview/cresmd-800.webp 800w,/assets/img/publication_preview/cresmd-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/cresmd.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cresmd.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="he2021interactive" class="col-sm-8"> <div class="title">Interactive Multi-Dimension Modulation for Image Restoration</div> <div class="author"> Jingwen He, Chao Dong, <em>Yihao Liu</em>, and Yu Qiao </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/l2m-480.webp 480w,/assets/img/publication_preview/l2m-800.webp 800w,/assets/img/publication_preview/l2m-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/l2m.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="l2m.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2021learn" class="col-sm-8"> <div class="title">Learn to Match: Automatic Matching Network Design for Visual Tracking</div> <div class="author"> Zhipeng Zhang, <em>Yihao Liu</em>, Xiao Wang, Bing Li, and Weiming Hu </div> <div class="periodical"> <em>In International Conference on Computer Vision (ICCV)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ddr-480.webp 480w,/assets/img/publication_preview/ddr-800.webp 800w,/assets/img/publication_preview/ddr-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/ddr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ddr.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2021discovering" class="col-sm-8"> <div class="title">Discovering" Semantics" in Super-Resolution Networks</div> <div class="author"> <em>Yihao Liu<sup>*</sup></em>, Anran Liu<sup>*</sup>, Jinjin Gu, Zhipeng Zhang, Wenhao Wu, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>arXiv preprint arXiv:2108.00406</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fdgan-480.webp 480w,/assets/img/publication_preview/fdgan-800.webp 800w,/assets/img/publication_preview/fdgan-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/fdgan.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fdgan.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="dong2020fd" class="col-sm-8"> <div class="title">FD-GAN: Generative Adversarial Networks with Fusion-Discriminator for Single Image Dehazing</div> <div class="author"> Yu Dong<sup>*</sup>, <em>Yihao Liu<sup>*</sup></em>, He Zhang, Shifeng Chen, and Yu Qiao </div> <div class="periodical"> <em>In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/csrnet-480.webp 480w,/assets/img/publication_preview/csrnet-800.webp 800w,/assets/img/publication_preview/csrnet-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/csrnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="csrnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="he2020conditional" class="col-sm-8"> <div class="title">Conditional Sequential Modulation for Efficient Global Image Retouching</div> <div class="author"> Jingwen He<sup>*</sup>, <em>Yihao Liu<sup>*</sup></em>, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCVW</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eqvi-480.webp 480w,/assets/img/publication_preview/eqvi-800.webp 800w,/assets/img/publication_preview/eqvi-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/eqvi.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eqvi.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2020enhanced" class="col-sm-8"> <div class="title">Enhanced Quadratic Video Interpolation</div> <div class="author"> <em>Yihao Liu<sup>*</sup></em>, Liangbin Xie<sup>*</sup>, Li Siyao, Wenxiu Sun, Yu Qiao, and Chao Dong </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV) Workshops</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> </div> <div id="zhang2019ranksrgan" class="col-sm-8"> <div class="title">RankSRGAN: Generative Adversarial Networks with Ranker for Image Super-Resolution</div> <div class="author"> Wenlong Zhang, <em>Yihao Liu</em>, Chao Dong, and Yu Qiao </div> <div class="periodical"> <em>In International Conference on Computer Vision (ICCV)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECCVW</abbr> </div> <div id="wang2018esrgan" class="col-sm-8"> <div class="title">ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks</div> <div class="author"> Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, <em>Yihao Liu</em>, Chao Dong, Yu Qiao, and Chen Change Loy </div> <div class="periodical"> <em>In Proceedings of the European conference on computer vision (ECCV) workshops</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://dblp.org/pid/200/6534-1.html" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> <a href="mailto:%6C%69%75%79%69%68%61%6F%31%34@%6D%61%69%6C%73.%75%63%61%73.%61%63.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> <a href="https://scholar.google.com/citations?user=WRIYcNwAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yihao LIU. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>